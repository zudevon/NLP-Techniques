{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acb3c160",
   "metadata": {},
   "source": [
    "# LangChain Fundamentals\n",
    "\n",
    "## 1. Introduction to LangChain\n",
    "\n",
    "LangChain is a framework for building applications with language models. It provides a set of tools and abstractions for working with language models, including:\n",
    "\n",
    "- Models: Language models like GPT-3, Claude, and more\n",
    "- Prompts: Templates for generating text\n",
    "- Chains: Sequential workflows for processing text\n",
    "- Agents: Autonomous agents that can perform tasks\n",
    "- Tools: Functions that can be called by an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "954dc766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm doing well, thank you for asking! I'm here to help with any questions or tasks you may have. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3.1:8b\", temperature=0, system=\"You are a helpful assistant.\")\n",
    "\n",
    "print(llm.invoke(\"Hello, how are you?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3cb552",
   "metadata": {},
   "source": [
    "Prompt a list or batch of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fd24703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Here's one:\\n\\nWhat do you call a fake noodle?\\n\\nAn impasta!\\n\\nI hope that made you smile! Do you want to hear another one?\", \"I have knowledge in various areas of mathematics, including:\\n\\n1. Algebra: equations, functions, graphs, and polynomial equations.\\n2. Geometry: points, lines, planes, angles, and shapes (2D and 3D).\\n3. Trigonometry: triangles, trigonometric functions (sine, cosine, tangent), and identities.\\n4. Calculus: limits, derivatives, integrals, and applications of calculus.\\n5. Statistics and Probability: data analysis, probability distributions, and statistical inference.\\n6. Number Theory: properties of integers, prime numbers, and modular arithmetic.\\n\\nI can help with:\\n\\n* Solving equations and inequalities\\n* Graphing functions and analyzing their behavior\\n* Calculating derivatives and integrals\\n* Working with vectors and matrices\\n* Understanding and applying mathematical concepts to real-world problems\\n\\nFeel free to ask me any math-related questions or problems you'd like help with!\"]\n"
     ]
    }
   ],
   "source": [
    "print(llm.batch(['Tell me a joke?', 'Do you know mathematics?']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb28618",
   "metadata": {},
   "source": [
    "Stream response in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bccf539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "'s\n",
      " one\n",
      ":\n",
      "\n",
      "\n",
      "Why\n",
      " did\n",
      " the\n",
      " dog\n",
      " with\n",
      " three\n",
      " legs\n",
      " go\n",
      " to\n",
      " therapy\n",
      "?\n",
      "\n",
      "\n",
      "Because\n",
      " it\n",
      " was\n",
      " struggling\n",
      " to\n",
      " balance\n",
      " its\n",
      " emotions\n",
      "!\n",
      " (\n",
      "get\n",
      " it\n",
      "?)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(\"Tell me a short joke about a dog with an extra leg.\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86154570",
   "metadata": {},
   "source": [
    "## Runnables\n",
    "\n",
    "langchain_core.runnables.base.Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "969e75a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "Why did the dog with three legs go to therapy?\n",
      "\n",
      "Because it was struggling to balance its emotions! (get it?)\n",
      "['Many things grow on trees! Here are some examples:\\n\\n1. Fruits: Apples, bananas, oranges, grapes, and many more.\\n2. Nuts: Walnuts, almonds, pecans, hazelnuts, and pine nuts.\\n3. Leaves: Of course, leaves are a fundamental part of what makes up the tree itself!\\n4. Flowers: Many trees produce beautiful flowers, like cherry blossoms or magnolia blooms.\\n5. Seeds: Trees produce seeds to propagate new growth, like acorns from oak trees or maple keys.\\n\\nWhat specific thing were you thinking of that grows on trees?']\n",
      "Here\n",
      "'s\n",
      " one\n",
      ":\n",
      "\n",
      "\n",
      "Why\n",
      " did\n",
      " the\n",
      " dog\n",
      " with\n",
      " three\n",
      " legs\n",
      " go\n",
      " to\n",
      " therapy\n",
      "?\n",
      "\n",
      "\n",
      "Because\n",
      " it\n",
      " was\n",
      " struggling\n",
      " to\n",
      " balance\n",
      " its\n",
      " emotions\n",
      "!\n",
      " (\n",
      "get\n",
      " it\n",
      "?)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(await llm.ainvoke(\"Tell me a short joke about a dog with an extra leg.\"))\n",
    "print(await llm.abatch([\"What grows on trees?\"]))\n",
    "async for chunk in llm.astream(\"Tell me a short joke about a dog with an extra leg.\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dc904fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris!\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke([{\"role\": \"user\", \"content\": \"What is the capital of France?\"}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f45f5f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sn/3p36yl6x21nb49xhnkm1x7kw0000gn/T/ipykernel_59439/2661274751.py:5: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  chat_llm = ChatOllama(model=\"llama3.1:8b\", temperature=0, system=\"You are a helpful assistant.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm just a computer program, so I don't have feelings or emotions like humans do. But thank you for asking! How can I assist you today? Do you have any questions or topics you'd like to discuss? I'm here to help with any information or tasks you need.\", additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2025-08-12T07:26:14.8008Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 1757183875, 'load_duration': 36327750, 'prompt_eval_count': 16, 'prompt_eval_duration': 194561083, 'eval_count': 59, 'eval_duration': 1525904208}, id='run--b654b472-25a0-4330-8fcf-e572a07b7e11-0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chat history\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "chat_llm = ChatOllama(model=\"llama3.1:8b\", temperature=0, system=\"You are a helpful assistant.\")\n",
    "\n",
    "chat_llm.invoke(\"Hello, how are you?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c85678e",
   "metadata": {},
   "source": [
    "# Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0abf6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='foo' additional_kwargs={} response_metadata={} type='human'\n",
      "content='foo' additional_kwargs={} response_metadata={}\n",
      "content='foo' additional_kwargs={} response_metadata={}\n",
      "content='foo' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "# Abstracting away the LLM\n",
    "# HumanMessage, BaseMessage, AIMessage, SystemMessage\n",
    "\n",
    "from langchain_core.messages import HumanMessage, BaseMessage, AIMessage, SystemMessage\n",
    "\n",
    "print(BaseMessage(content=\"foo\", type=\"human\"))\n",
    "\n",
    "print(HumanMessage(content=\"foo\"))\n",
    "\n",
    "print(AIMessage(content=\"foo\"))\n",
    "\n",
    "print(SystemMessage(content=\"foo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34e63640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human\n",
      "ai\n",
      "system\n"
     ]
    }
   ],
   "source": [
    "print(HumanMessage(content=\"hello there\").type)\n",
    "print(AIMessage(content=\"foo\").type)\n",
    "print(SystemMessage(content=\"foo\").type)\n",
    "# print(BaseMessage(content=\"foo\").type) -- Doesn't work, doesnt' have a type attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e43299",
   "metadata": {},
   "source": [
    "# Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d83f2b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='You are a helpful assistant that and your name is Devon.' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import SystemMessagePromptTemplate\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are a helpful assistant that and your name is {name}.\"\n",
    "    )\n",
    "\n",
    "system_prompt = system_message_prompt.format(name=\"Devon\")\n",
    "\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27b02a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a helpful assistant.\n",
      "AI: Hello, how are you?\n",
      "Human: What is your name?\n",
      "AI: My name is Devon.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"ai\", \"Hello, how are you?\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"My name is {name}.\")\n",
    "    ])\n",
    "\n",
    "prompt_value = chat_prompt.format(name=\"Devon\", input=\"What is your name?\")\n",
    "print(prompt_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9826183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, how are you?', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={}), AIMessage(content='My name is Devon.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "prompt_value = chat_prompt.invoke(\n",
    "    {\n",
    "        \"name\": \"Devon\",\n",
    "        \"input\": \"What is your name?\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80bad122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='Hello, my name is Devon.'\n"
     ]
    }
   ],
   "source": [
    "# it's a runnable!! \n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"name\"],\n",
    "    template=\"Hello, my name is {name}.\"\n",
    ")\n",
    "\n",
    "print(prompt.invoke({\"name\": \"Devon\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e629e86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful assistant. Your name is Devon.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# All together now\n",
    "\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate\n",
    "\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are a helpful assistant. Your name is {name}.\"\n",
    "    )\n",
    "\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_prompt,\n",
    "    (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "prompt_value = chat_prompt.invoke({\"name\": \"Devon\", \"input\": \"What is your name?\"})\n",
    "\n",
    "print(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "067ecd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"My name is Devon, and I'm here to help with any questions or tasks you may have! How can I assist you today?\" additional_kwargs={} response_metadata={'model': 'llama3.1:8b', 'created_at': '2025-08-12T07:45:46.197173Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 1949061875, 'load_duration': 932646042, 'prompt_eval_count': 31, 'prompt_eval_duration': 305828625, 'eval_count': 28, 'eval_duration': 708489958} id='run--53866c8a-c3c1-429f-9517-50916e8433d7-0'\n"
     ]
    }
   ],
   "source": [
    "print(chat_llm.invoke(prompt_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe84415",
   "metadata": {},
   "source": [
    "# Pipes, Chains, and Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4fd785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"My name is Devon, and I'm here to help with any questions or tasks you may have! How can I assist you today?\" additional_kwargs={} response_metadata={'model': 'llama3.1:8b', 'created_at': '2025-08-12T07:51:55.532517Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 1627031667, 'load_duration': 693638250, 'prompt_eval_count': 31, 'prompt_eval_duration': 225931167, 'eval_count': 28, 'eval_duration': 706490583} id='run--a1b3769e-4a11-4dc0-a82d-6f036bf2bc82-0'\n"
     ]
    }
   ],
   "source": [
    "# from langchain_core.runnables import RunnableSequence --- NOT the right class\n",
    "\n",
    "# These all do the same thing\n",
    "chain = chat_prompt | chat_llm\n",
    "chain = chat_prompt.pipe(chat_llm)\n",
    "chain = chat_prompt.__or__(chat_llm)\n",
    "\n",
    "# chain = RunableSequence(first=chat_prompt, second=chat_llm)\n",
    "\n",
    "\n",
    "print(chain.invoke({\n",
    "    \"name\": \"Devon\",\n",
    "    \"input\": \"What is your name?\" \n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8994d3",
   "metadata": {},
   "source": [
    "# Output Parser + more Chain!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "857196b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Devon, and I'm here to help with any questions or tasks you may have! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = chat_prompt | chat_llm | StrOutputParser()\n",
    "\n",
    "print(chain.invoke({\n",
    "    \"name\": \"Devon\",\n",
    "    \"input\": \"What is your name?\" \n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad94abb",
   "metadata": {},
   "source": [
    "### A generated Agent - THis is the only generated code i'm ever going to post lol... maybe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e714c14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a simple agent with tools\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain_core.tools import tool\n",
    "from langchain import hub\n",
    "\n",
    "# Define a simple tool\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Calculate the result of a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def string_length(text: str) -> str:\n",
    "    \"\"\"Return the length of a string.\"\"\"\n",
    "    return str(len(text))\n",
    "\n",
    "# Create list of tools\n",
    "tools = [calculator, string_length]\n",
    "\n",
    "# Get a react prompt from the hub\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "# Create the agent\n",
    "agent = create_react_agent(chat_llm, tools, prompt)\n",
    "\n",
    "# Create an agent executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Test the agent\n",
    "result = agent_executor.invoke({\n",
    "    \"input\": \"What is 25 * 4? Also, what is the length of the word 'LangChain'?\"\n",
    "})\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
